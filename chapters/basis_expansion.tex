\documentclass[../main/report.tex]{subfiles}
\begin{document}
	
\chapter{The Basis Expansion Method}
\label{cha:basis_expansion}

The present chapter introduces the basis expansion method of solving the \emph{Time Independent Schrödinger Equation} (TISE).
We begin by motivating the method and showing how it can be used to write the TISE as a matrix equation. 
This is followed by two examples to be used in later chapters: the harmonic oscillator basis and the momentum basis.
Finally we discuss the numerical aspects of basis expansion.

\section{Introduction to Basis Expansion}

We want to study loosely bound quantum systems by solving the TISE
\begin{eq}
  \label{eq:TISE}
  H \ket\psi = E \ket\psi,
\end{eq}
commonly written
\begin{eq}
  \label{eq:TISEpos}
  \p{-\frac{\hbar^2}{2m}\nabla^2 + V(\vec{r})}\psi(\vec{r}) = E\psi(\vec{r}).
\end{eq}
For the nuclear systems to be treated, the TISE has no known analytical solutions, and we need to use numerical methods to solve it.
We do this by writing the equation as an eigenvalue problem
\begin{eq}
  \label{eq:matrix equation}
  \sum_j H_{ij}\psi_j = E \psi_i
\end{eq}
with a finite matrix $H$ that we can diagonalize to find the eigenvalues $E$.

To write the TISE as a matrix equation we use \emph{basis expansion}. 
Basis expansion is how we make sense of the abstract Hilbert spaces, operators and state vectors of Quantum Mechanics (QM).
By expanding these abstract objects in a basis, we can relate them to the physical world. 
For example, \cref{eq:TISEpos} is the TISE for a single particle, expanded in the position basis. 
We will not expand our problems in the position basis. The position basis is still important because it is the most natural basis to express potentials in, since potentials are often functions of position.

Before we begin, we briefly recap some well known QM facts. 
First we need a \emph{complete basis}, either discrete, $\ket{n}$, or continuous, $\ket{x}$. 
A complete basis means that any state $\ket\psi$ can be written as a linear combination of the basis states
\begin{eq}
  \label{eq:lincomb}	
  \ket\psi = \sum_n \psi_n \ket{n}
  \quad
  \textup{or}
  \quad
  \ket\psi = \fint{x} \psi(x) \ket{x}.
\end{eq}
The  complete bases we will use in this thesis are the \emph{position basis} $\ket{\vec{r}}$, the \emph{momentum basis} $\ket{\vec{k}}$, the \emph{harmonic oscillator basis} $\ket{nlm}$ and the elusive \emph{Berggren basis} \cite{berggren}. 
All these bases are orthonormal, i.e.~all the basis vectors satisfy 
\begin{eq}
  \braket{n}{n'} = \delta_{nn'}
  \quad
  \textup{or}
  \quad
  \braket{x}{x'} = \delta(x - x'),
\end{eq}
depending on if the base is discrete or continuous.
With a complete basis $\ket{n}$, we get the very useful \emph{completeness relation}
\begin{eq}
  I = \sum_n \ket{n} \bra{n}
  \quad
  \textup{or}
  \quad
  I = \fint{x} \ket{x}\bra{x},
\end{eq}
where $I$ is the identity operator. This relation can thus be inserted anywhere in any equation, and will find frequent use in this thesis.

Let us now expand the TISE in the abstract $\ket{n}$ basis. We start by inserting the completeness relation for $\ket{n}$ in \cref{eq:TISE}
\begin{eq}
  \label{eq:expand1}
  H
  \p{
    \sum_{n'} \ket{n'} \bra{n'}
  }
  \ket\psi
  =
  \sum_{n'} H \ket{n'} \braket{n'}{\psi}
  =
  E \ket\psi.
\end{eq}
Closing \cref{eq:lincomb} with $\bra{n}$ from the left and using orthonormality, we see that $\braket{n'}{\psi} = \psi_{n'}$. If we now close \cref{eq:expand1} with $\bra{n}$ on the left
\begin{eq}
  \label{eq:expand2}
  \sum_{n'} \bra{n} H \ket{n'} \psi_{n'}
  = 
  E \braket{n}{\psi},
\end{eq}
and write $H_{nn'} = \bra{n} H \ket{n'}$, we get
\begin{eq}
  \label{eq:expand3}
  \sum_{n'} H_{nn'} \psi_{n'} = E \psi_n,
\end{eq}
which is equivalent to the matrix equation \cref{eq:matrix equation}. This is 
the basic method of expanding the TISE in a basis.

\section{Spherical Symmetry}
\label{sec:spherical symmetry}

We limit ourselves to spherically symmetric systems, i.e. systems with a potential $V(r)$ that only depends on the radial distance $r$.
If we considered three-dimensional systems with arbitrary potentials, the matrices would be very large and solving the problem numerically would become infeasible.

Spherical symmetry allows us to write the wavefunction $\psi(\vec{r})$ as a product of a radial wavefunction $R(r)$ and a spherical harmonic $Y_l^m(\Omega_r)$
\begin{eq}
  \psi(\vec{r}) = R_{nl}(r) Y_l^m(\Omega_r).
\end{eq}
Here $l$ and $m$ are the quantum numbers for the orbital angular momentum and its projection along an arbitrary $z$-axis.
For the matrix elements we find, using the orthonormality of the spherical harmonics,
\begin{eq}
  \bra{nlm}V\ket{n'l'm'} 
  &= \fint[0][\inf]{r} 
    r^2 \conj{R_{nl}(r)}R_{n'l'}(r)V(r) 
    \fint{\Omega_r} 
      \conj{Y_l^m(\Omega_r)}Y_{l'}^{m'}(\Omega_r)
  \\ & = 
  \delta_{mm'}\delta_{ll'}\fint[0][\inf]{r} 
    r^2 \conj{R_{nl}(r)}R_{n'l'}(r)V(r)
\end{eq}
meaning that the matrix will be \emph{block diagonal}, illustrated in \cref{fig:bmatrix}. This means that systems with different $l$ and $m$ can be treated separately. We say that \emph{$H$ is diagonal in $l$ and $m$}.

\begin{figure}[b!]
\center
\includegraphics{../figures/block_matrix/matrix.pdf}
\caption{An illustration of a block diagonal matrix. The eigenvalues of different blocks are independent of each other. Thus the blocks can be diagonalized separately.}
\label{fig:bmatrix}
\end{figure}

\section{The Harmonic Oscillator Basis}
\label{sec:harmosc}

We now expand the TISE in the spherically symmetric Harmonic Oscillator (HO) basis. The basis consists of the eigenstates $\ket{nlm}$ of the HO Hamiltonian
\begin{eq}
  \label{eq:HO_hamiltonian}
  H\sub{HO} = \frac{p^2}{2\mu} + \frac{\mu\omega^2 r^2}{2},
\end{eq}
where $\mu$ is the mass and $\omega$ is the angular frequency of the oscillator. 
The expansion procedure is the same as in \cref{eq:expand1,eq:expand2,eq:expand3} and gives us
\begin{eq}
  \sum_{n'l'm'} \bra{nlm} H \ket{n'l'm'} \psi_{n'l'm'} = E \psi_{nlm}
\end{eq}
and if we use the fact that $H$ is diagonal in $l$ and $m$ we get
\begin{eq}
  \sum_{n'} \bra{nlm} H \ket{n'lm} \psi_{n'lm} = E\psi_{nlm}.
\end{eq}
We now have a matrix equation, but we need to find the matrix elements $\bra{nlm} H \ket{n'lm}$. This require some calculation (details are presented in \cref{sec:HO matrix elements}) and the result is
\begin{eq}
  \label{eq:HO_matrix_elements}
  &
  \bra{nlm} H \ket{n'lm} =
	\frac{\hbar\omega}{2}
	\left(
    \p{2n+l+\frac{3}{2}} \delta_{nn'}
    +
		\sqrt{n(n+l+\frac{1}{2})} \delta_{n,n'-1}\right.
		\\ & + 
		\left.\sqrt{n'(n'+l+\frac{1}{2})} \delta_{n',n-1} 
	\right)
	+
	\fint[0][\inf]{r} 
    r^2 R_{nl}(r) V(r) R_{n'l}(r)
\end{eq}
where $R_{nl}$ are the radial wavefunctions of the harmonic oscillator,
\begin{eq}
  \label{eq:HO_radial_wavefunction}
	R_{nl}(r) 
	= 
 \sqrt{\frac{2 \, (\frac{n-l}{2})! }{\Gamma(\frac{n+l}{2}+\frac{3}{2})}}
\frac{r^l}{r_0^{l+{3\over 2}}} \exp\p{-\frac{r^2}{2r_0^2}}
	L_{(n-l) / 2}^{(l+\frac{1}{2})}\p{\frac{r^2}{r_0^2}},
\end{eq}
$r_0 = \sqrt{\hbar/\mu\omega}$ can be considered a range of the harmonic oscillator, and $L_\nu^\lambda(x)$ are the generalized Laguerre polynomials.
The radial wavefunction $R(r)$ of a state will be expressed as a linear combination of the harmonic oscillator radial wavefunctions:
\begin{eq}
  R(r) = \sum_n \psi_{nl} R_{nl}(r).
\end{eq}

\section{The Momentum Basis}
\label{sec:mom_space}
The momentum, or plane wave, basis has eigenstates $\ket{\vec{k}}$, each describing a free particle with momentum $\vec{p}$ or wavevector $\vec{k} = \vec{p}/\hbar$. We will only use $\vec{k}$ and refer to it as momentum.

The expansion is done in the same way as before, giving us
\begin{eq}
  \int \rd^3 \vec{k}' \bra{\vec{k}} H \ket{\vec{k}'} \Phi(\vec{k}')
  &= 
  E\Phi(\vec{k}),
\end{eq}
where we denote the momentum wavefunctions with $\Phi$. 
As in position space, these can be separated into a radial and angular part.
This is shown in \cref{app:radial_mom_TISE} along with the fact that the Schrödinger equation can be written as
\begin{align}
  \label{eq:radial mom space TISE}
  H\phi(k)
  & =
  \frac{k^2}{2\mu}\phi(k) + \fint[0][\inf]{k'} k'^2 V(k,k') \phi(k'),
  =
  E\phi(k)
\end{align}
with
\begin{align}
  V(k,k') 
  & = 
  \frac{2}{\pi}\fint[0][\inf]{r} r^2 V(r) j_l(kr) j_l(k'r)
\end{align}
where $\phi(k)$ is the radial part of the momentum wavefunction
and $j_l(kr)$ are the spherical bessel functions of order $l$. 
The radial-momentum wavefunction $\phi(k)$ is related to the radial-position wavefunction by
\begin{eq}
  R(r)=i^l\sqrt{\frac{2}{\pi}} \fint[0][\inf]{k} k^2 \phi(k)j_l(kr).
  \label{eq:radial wavefunction}
\end{eq}

\subsection{Discretization and Symmetrization}
\label{sec:discretization}
The integral equation \cref{eq:radial mom space TISE} can be rewritten as a matrix equation through discretization, turning the integral into a sum over a finite set of points $k_j$ and $\rd{k}$ into a set of weights $w_j$:
\begin{eq}
  \label{eq:discrete_momentum}
  \frac{k_i^2}{2\mu} \phi(k_i)
  +
  \sum_{j=1}^N w_j
    k_j^2 V(k_i,k_j)
  \phi(k_j)
  =
  E \phi(k_i)
  .
\end{eq}
A particular set of points and corresponding weights is called a \emph{quadrature}, and the choice of quadrature greatly impacts the precision of the result. 
A naïve quadrature with evenly spaced $k_j = j\Delta k$ and a constant weight $w_j=\Delta k$ converges slowly, and should not be used.
We instead use the Gauss-Legendre quadrature, for details see \cref{app:gauss-legendre}.

With this discretization the Schrödinger equation may be written as 
\begin{eq}
  \sum_j H_{ij} \phi(k_j) &= E \phi(k_i)
\end{eq}
where
\begin{align}
  \label{eq:mom_matrix}
  H_{ij} &= \frac{k_i^2}{2\mu}\delta_{ij} + w_jk_j^2 V_{ij} \\
  \label{eq:potential matrix}
  V_{ij} &= \frac{2}{\pi} \fint[0][\inf]{r} r^2 V(r) j_l(k_i r) j_l(k_j r).
\end{align}

Because of the $k_j^2$ in the second term of the matrix elements 
\cref{eq:mom_matrix}, the $H_{ij}$ matrix will not be symmetric. 
Working with a symmetric matrix is faster, which will be explained in the following section. 
We perform the transformation
\begin{eq}
  \phi(k_i) &\mapsto
  \phi'(k_i) =  \sqrt{w_i} k_i \phi(k_i)
  \\
  H_{ij} &\mapsto
  H_{ij}' 
  = 
  \sqrt{\frac{w_i}{w_j}} \frac{k_i}{k_j}H_{ij},
\end{eq}
which gives us a symmetric matrix
\begin{eq}
  \label{eq:plane_wave_matrix_elements}
  H_{ij}' = \frac{k_i^2}{2\mu}\delta_{ij} + \sqrt{w_i w_j}k_i k_j V_{ij}.
\end{eq}
The Schrödinger equation then becomes
\begin{eq}
  \sum_j H'_{ij}\phi'(k_j) = E\phi'(k_i),
\end{eq}
with the same eigenvalues $E$, meaning that we can work with the symmetric $H'_{ij}$ matrix.
Another benefit of the symmetrization is that the norm of the $\phi'(k_i)$ incorporates the weights $w_i k_i^2$.
The real space radial wavefunction $R(r)$ is expressed in terms of $\phi'(k_j)$ as
\begin{eq}
  R(r)
  =
  i^l 
  \sqrt{\frac{2}{\pi}}
  \sum_{j=1}^N 
    \sqrt{w_j}k_j \phi'_j j_l(k_j r).
\end{eq}

\section{Numerical Considerations}

In order to perform basis expansion on a computer, we need to consider the numerical aspects of the problem. 
This includes truncation of the basis, matrix size reduction, numerical integration and eigensolver optimizations.
The momentum basis is continuous and thus requires special treatment.

The $\ket{nlm}$ and $\ket{k}$ bases are infinite, so we truncate them by only including a finite number $N$ of states in the basis. 
For an orthonormal basis, the best approximation is to include the $N$ first states.
The more states we include in the basis, the more accurate results we get.

The truncation gives us an $N \times N$ Hamiltonian matrix $H$ and the TISE can be written in matrix notation as
\begin{eq}
  \label{eq:matrix eq}
  H\psi = E\psi,
\end{eq}
where the $\psi$ are eigenvectors. We compute the matrix elements $H_{ij}$ with \cref{eq:HO_matrix_elements,eq:plane_wave_matrix_elements}, carrying out the integrals with the Gauss-Legendre quadrature rule (see \cref{app:gauss-legendre}) and setting the upper limit to a finite number.
If the matrix is hermitian or symmetric, we only need to consider the elements in the upper triangle including the diagonal, roughly halving the number of computed elements. 

When the matrix elements have been computed, the matrix is diagonalized using a standard eigensolver algorithm. For hermitian matrices there are specialized, faster algorithms.

\end{document}
